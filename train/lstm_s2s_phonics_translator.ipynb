{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOWc-gQBf1TA"
   },
   "source": [
    "# Phonics-level recurrent sequence-to-sequence translation model\n",
    "\n",
    "**Author:** Tsz Lung<br>\n",
    "**Date created:** 2021/09/29<br>\n",
    "**Last modified:** 2021/09/29<br>\n",
    "**Description:** phonics-level recurrent sequence-to-sequence translation model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dULejMDf1TF"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This example demonstrates how to implement a basic phonics-level\n",
    "recurrent sequence-to-sequence translation model. We apply it to translating\n",
    "single word with accent into single word with standard phoneme,\n",
    "phoneme-by-phoneme. Note that it is fairly unusual to\n",
    "do phoneme-level machine translation, as word-level\n",
    "models are more common in this domain.\n",
    "\n",
    "**Summary of the algorithm**\n",
    "\n",
    "- We start with input sequences from a domain (e.g. single word)\n",
    "    and corresponding target sequences from another domain\n",
    "    (e.g. single word).\n",
    "- An encoder LSTM turns input sequences to 2 state vectors\n",
    "    (we keep the last LSTM state and discard the outputs).\n",
    "- A decoder LSTM is trained to turn the target sequences into\n",
    "    the same sequence but offset by one timestep in the future,\n",
    "    a training process called \"teacher forcing\" in this context.\n",
    "    It uses as initial state the state vectors from the encoder.\n",
    "    Effectively, the decoder learns to generate `targets[t+1...]`\n",
    "    given `targets[...t]`, conditioned on the input sequence.\n",
    "- In inference mode, when we want to decode unknown input sequences, we:\n",
    "    - Encode the input sequence into state vectors\n",
    "    - Start with a target sequence of size 1\n",
    "        (just the start-of-sequence character)\n",
    "    - Feed the state vectors and 1-char target sequence\n",
    "        to the decoder to produce predictions for the next phoneme\n",
    "    - Sample the next phoneme using these predictions\n",
    "        (we simply use argmax).\n",
    "    - Append the sampled phoneme to the target sequence\n",
    "    - Repeat until we generate the end-of-sequence character or we\n",
    "        hit the character limit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bL-J-v-af1TH"
   },
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2p0kZ6qEf1TH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import re\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load phonics dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('cmusphinxdict.json') as f:\n",
    "  phoneme_dictionary = json.load(f)\n",
    "\n",
    "#cmu phoneme list\n",
    "cmu_phoneme = [\n",
    "            'SPACE',\n",
    "            'AA',\n",
    "            'AE',\n",
    "            'AH',\n",
    "            'AO',\n",
    "            'AW',\n",
    "            'AY',\n",
    "            'B',\n",
    "            'CH',\n",
    "            'D',\n",
    "            'DH',\n",
    "            'EH',\n",
    "            'ER',\n",
    "            'EY',\n",
    "            'F',\n",
    "            'G',\n",
    "            'HH',\n",
    "            'IH',\n",
    "            'IY',\n",
    "            'JH',\n",
    "            'K',\n",
    "            'L',\n",
    "            'M',\n",
    "            'N',\n",
    "            'NG',\n",
    "            'OW',\n",
    "            'OY',\n",
    "            'P',\n",
    "            'R',\n",
    "            'S',\n",
    "            'SH',\n",
    "            'T',\n",
    "            'TH',\n",
    "            'UH',\n",
    "            'UW',\n",
    "            'V',\n",
    "            'W',\n",
    "            'Y',\n",
    "            'Z',\n",
    "            'ZH',\n",
    "        ] \n",
    "\n",
    "\n",
    "def word_to_phonics(input_word):\n",
    "    phonics_blending = []\n",
    "    for word in phoneme_dictionary:\n",
    "        if (input_word == word):\n",
    "#             print(input_word)\n",
    "            for phoneme in phoneme_dictionary[word]:\n",
    "                phoneme = re.split(' ',phoneme)\n",
    "                phonics_blending.append(phoneme)\n",
    "       \n",
    "    return phonics_blending\n",
    "\n",
    "def get_phoneme_index(input_phoneme):\n",
    "    phoneme_index = 0\n",
    "    \n",
    "    for phoneme in cmu_phoneme:\n",
    "        if (phoneme.upper() == input_phoneme):\n",
    "            break\n",
    "\n",
    "        phoneme_index += 1\n",
    "    \n",
    "    return phoneme_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvL61cnvf1TL"
   },
   "source": [
    "## Prepare the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "tJ6HRZqjFnee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training data 739\n"
     ]
    }
   ],
   "source": [
    "#read training data\n",
    "input_data_list = []\n",
    "output_data_list = []\n",
    "with open('wordfun_phonics.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "count = 0    \n",
    "for line in lines:\n",
    "    count += 1\n",
    "    #print(f'line {count}: {line}')    \n",
    "    input_output = re.split('; |, |\\n',line)\n",
    "    #output = input_output[0]\n",
    "    #print(output)\n",
    "    wordCount =0\n",
    "    output_word = ''\n",
    "    for word in input_output:\n",
    "        if wordCount == 0:\n",
    "            output_word = word\n",
    "        else:\n",
    "            if word != '':\n",
    "                input_data_list.append(word)\n",
    "                output_data_list.append(output_word)\n",
    "        \n",
    "        wordCount += 1\n",
    "        \n",
    "print(f'size of training data {len(input_data_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "RCSquZXcsfVZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH', 'D', 'DH', 'EH', 'ER', 'EY', 'F', 'G', 'HH', 'IH', 'IY', 'JH', 'K', 'L', 'M', 'N', 'NG', 'OW', 'OY', 'P', 'R', 'S', 'SH', 'T', 'TH', 'UH', 'UW', 'V', 'W', 'Y', 'Z']\n",
      "['\\t', '\\n', 'AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH', 'D', 'DH', 'EH', 'ER', 'EY', 'F', 'G', 'HH', 'IH', 'IY', 'JH', 'K', 'L', 'M', 'N', 'NG', 'OW', 'OY', 'P', 'R', 'S', 'SH', 'T', 'TH', 'UH', 'UW', 'V', 'W', 'Y', 'Z']\n",
      "Number of samples: 739\n",
      "size of training data 986\n",
      "Number of unique input tokens: 38\n",
      "Number of unique output tokens: 40\n",
      "Max sequence length for inputs: 10\n",
      "Max sequence length for outputs: 12\n"
     ]
    }
   ],
   "source": [
    "## Convert word list to phonemic list\n",
    "\n",
    "input_data_phonics_list = []\n",
    "output_data_phoics_list = []\n",
    "\n",
    "input_phonemes = set()\n",
    "target_phonemes = set() \n",
    "\n",
    "input_data_index = 0\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_encoded_0 = label_encoder.fit_transform(output_data_list)\n",
    "# y_encoded = to_categorical(y_encoded_0)\n",
    "\n",
    "# total_output_classes = len(label_encoder.classes_)\n",
    "# print(f'total_output_classes {total_output_classes}')\n",
    "# print(f'total y_encoded {len(y_encoded)}')\n",
    "\n",
    "# #generate dummy data by duplicate current data\n",
    "# for class_label in label_encoder.classes_:\n",
    "#     for index in range(50):\n",
    "#         input_data_list.append(class_label)\n",
    "#         output_data_list.append(class_label)\n",
    "\n",
    "# y_encoded_0 = label_encoder.fit_transform(output_data_list)\n",
    "# y_encoded = to_categorical(y_encoded_0)\n",
    "\n",
    "# print(f'size of training data  with dummy data {len(input_data_list)}')\n",
    "# print(f'total y_encoded {len(y_encoded)}')\n",
    "\n",
    "for input_data in input_data_list:\n",
    "#     print(input_data.upper())\n",
    "#     print(output_data_list[input_data_index].upper())\n",
    "#     print(y_encoded_0[input_data_index])\n",
    "\n",
    "    seperated_input_word_list = re.split(' ',input_data.upper())\n",
    "    \n",
    "    for single_input_word in seperated_input_word_list:\n",
    "        \n",
    "        for phonics_blending in word_to_phonics(single_input_word):\n",
    "#             print(phonics_blending)\n",
    "            single_word_phoneme_blending_index = []\n",
    "            for phoneme in phonics_blending:\n",
    "                #print(get_phoneme_index(phoneme))\n",
    "                single_word_phoneme_blending_index.append(phoneme)\n",
    "                \n",
    "#             print(output_data_list[input_data_index])\n",
    "            for target_word_phoneme in word_to_phonics(output_data_list[input_data_index].upper()):\n",
    "#                 print(target_word_phoneme)\n",
    "                target_word_phoneme_blending_index = []\n",
    "                target_word_phoneme_blending_index.append('\\t')\n",
    "                for phoneme in target_word_phoneme:\n",
    "                    #print(get_phoneme_index(phoneme))\n",
    "                    target_word_phoneme_blending_index.append(phoneme)\n",
    "                target_word_phoneme_blending_index.append('\\n')\n",
    "                    \n",
    "                input_data_phonics_list.append(single_word_phoneme_blending_index)\n",
    "                output_data_phoics_list.append(target_word_phoneme_blending_index) \n",
    "                \n",
    "                for phoneme in single_word_phoneme_blending_index:\n",
    "#                     print(phoneme)\n",
    "                    if phoneme not in input_phonemes:\n",
    "                        input_phonemes.add(phoneme)\n",
    "                for phoneme in target_word_phoneme_blending_index:\n",
    "                    if phoneme not in target_phonemes:\n",
    "                        target_phonemes.add(phoneme)\n",
    "\n",
    "            #insert space after word\n",
    "            #single_word_phoneme_blending_index.append(get_phoneme_index('SPACE'))\n",
    "            \n",
    "#             #add ending padding\n",
    "#             end_padding = range(SEQUENCE_MAX_LENGTH-len(single_word_phoneme_blending_index))\n",
    "#             for end_padding_index in end_padding:\n",
    "#                 #set the padding valoue to 100\n",
    "#                 single_word_phoneme_blending_index.append(get_phoneme_index('SPACE'))\n",
    "            \n",
    "            \n",
    "            #print(single_word_phoneme_blending_index)\n",
    "            #print(y_encoded[input_data_index])\n",
    "     \n",
    "    \n",
    "    #add ending padding\n",
    "    \n",
    "    input_data_index += 1\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "# print(input_phonemes)\n",
    "# print(target_phonemes)\n",
    "\n",
    "input_phonemes = sorted(list(input_phonemes))\n",
    "target_phonemes = sorted(list(target_phonemes))\n",
    "num_encoder_tokens = len(input_phonemes)\n",
    "num_decoder_tokens = len(target_phonemes)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_data_phonics_list])\n",
    "max_decoder_seq_length = max([len(txt) for txt in output_data_phoics_list])\n",
    "\n",
    "\n",
    "\n",
    "print(input_phonemes)\n",
    "print(target_phonemes)\n",
    "\n",
    "print(\"Number of samples:\", len(input_data_list))\n",
    "print(f'size of training data {len(input_data_phonics_list)}')\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
    "\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_phonemes)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_phonemes)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_data_phonics_list), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_data_phonics_list), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_data_phonics_list), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_data_phonics_list, output_data_phoics_list)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "#     encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    # decoder_input_data[i, t + 1 :, target_token_index[' ']] = 1.0\n",
    "    # decoder_target_data[i, t:, target_token_index[' ']] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNG-3_kLf1TK"
   },
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9JeWmazVf1TK"
   },
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 500  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "#num_samples = 1000  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "# data_path = \"yue.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcJMrm4Jf1TO"
   },
   "source": [
    "## Build the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "12rOGCImf1TO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-01 11:57:37.169335: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
    "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYCGFp2Pf1TP"
   },
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PUNihDKJf1TP",
    "outputId": "bbbfb19b-4692-4a87-fb83-6a3728869dfd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-01 11:57:45.952203: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kd/nyt5y4cn4tvbc60yt2dmwn6c0000gp/T/ipykernel_57606/2810769409.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rmsprop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 4\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mencoder_input_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdecoder_target_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bi-directional_lstm_translator/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bi-directional_lstm_translator/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bi-directional_lstm_translator/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bi-directional_lstm_translator/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bi-directional_lstm_translator/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bi-directional_lstm_translator/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bi-directional_lstm_translator/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "# Save model\n",
    "# model.save(\"phonics2phonics\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save(\"phonics2phonics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsWCCMSaf1TQ"
   },
   "source": [
    "## Run inference (sampling)\n",
    "\n",
    "1. encode input and retrieve initial decoder state\n",
    "2. run one step of decoder with this initial state\n",
    "and a \"start of sequence\" token as target.\n",
    "Output will be the next target token.\n",
    "3. Repeat with the current target token and current states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qENTmoLqf1TQ"
   },
   "outputs": [],
   "source": [
    "# Define sampling models\n",
    "# Restore the model and construct the encoder and decoder.\n",
    "model = keras.models.load_model(\"phonics2phonics\")\n",
    "\n",
    "encoder_inputs = model.input[0]  # input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]  # input_2\n",
    "decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "#         if (sampled_char !='\\t' or sampled_char != '\\n'):\n",
    "        decoded_sentence += sampled_char + ' '\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfR3cDMnf1TQ"
   },
   "source": [
    "You can now generate decoded sentences as such:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EqByMn1lG4Zv",
    "outputId": "eb03c640-89dc-4826-c967-a03b0bf16e06"
   },
   "outputs": [],
   "source": [
    "while(True):\n",
    "    i=0\n",
    "    input_data = input(\"Enter your word: \")\n",
    "    \n",
    "    phoneme_blendings = word_to_phonics(input_data.upper())\n",
    "    \n",
    "    for phoneme_blending in phoneme_blendings:\n",
    " \n",
    "\n",
    " \n",
    "    #     for phonics_blending in word_to_phonics(input_data.upper()):\n",
    "        encoder_input_data_1 = np.zeros((1, max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\")\n",
    "    #     for t, char in enumerate(input_data.upper()):\n",
    "\n",
    "        input_word_phoneme = ''\n",
    "        for t in range(len(phoneme_blending)):\n",
    "           \n",
    "            char = phoneme_blending[t]\n",
    "            input_word_phoneme += char + ' '\n",
    "    #         print(char)\n",
    "    #         print(t)\n",
    "            encoder_input_data_1[i, t, input_token_index[char]] = 1.0\n",
    "    #     encoder_input_data_1[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "\n",
    "        # print(encoder_input_data_1[0,1])\n",
    "        input_seq = encoder_input_data_1[0 :  1]\n",
    "        # print(input_seq)\n",
    "        decoded_sentence = decode_sequence(input_seq)\n",
    "        # decoded_sentence = decode_sequence(encoder_input_data_1[0:1])\n",
    "        # print(\"-\")\n",
    "        #print(\"Input sentence:\", input_texts[seq_index])\n",
    "    #     decoded_output = re.split('\\t|, |\\n',decoded_sentence)\n",
    "\n",
    "    #     decoded_sentence = ''\n",
    "    #     for ouput in decoded_output:\n",
    "    #         if output != '':\n",
    "    #             decoded_sentence = decoded_sentence + output\n",
    "        print(\"Input word phonics blending:\", input_word_phoneme)\n",
    "        print(\"Decoded word phonics blending:\", decoded_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YpJAypJlf1TR",
    "outputId": "af68e87d-92bb-4f12-bb6c-1ed907c840dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: ['R', 'EH', 'D']\n",
      "Decoded sentence: R EH D \n",
      " \n",
      "-\n",
      "Input sentence: ['G', 'L', 'AE', 'D']\n",
      "Decoded sentence: R EH D \n",
      " \n",
      "-\n",
      "Input sentence: ['R', 'EH', 'D']\n",
      "Decoded sentence: R EH D \n",
      " \n",
      "-\n",
      "Input sentence: ['R', 'IY', 'D']\n",
      "Decoded sentence: R AE B AH T \n",
      " \n",
      "-\n",
      "Input sentence: ['R', 'AE', 'T']\n",
      "Decoded sentence: R EH D \n",
      " \n",
      "-\n",
      "Input sentence: ['G', 'R', 'IY', 'N']\n",
      "Decoded sentence: G R IY N \n",
      " \n",
      "-\n",
      "Input sentence: ['K', 'L', 'IY', 'N']\n",
      "Decoded sentence: G R IY N \n",
      " \n",
      "-\n",
      "Input sentence: ['G', 'R', 'EY', 'T']\n",
      "Decoded sentence: G R IY N \n",
      " \n",
      "-\n",
      "Input sentence: ['B', 'L', 'UW']\n",
      "Decoded sentence: B L UW \n",
      " \n",
      "-\n",
      "Input sentence: ['HH', 'AH', 'L', 'OW']\n",
      "Decoded sentence: HH EH R \n",
      " \n",
      "-\n",
      "Input sentence: ['HH', 'EH', 'L', 'OW']\n",
      "Decoded sentence: HH EH R \n",
      " \n",
      "-\n",
      "Input sentence: ['W', 'AY', 'T']\n",
      "Decoded sentence: HH W AY T \n",
      " \n",
      "-\n",
      "Input sentence: ['W', 'AY', 'T']\n",
      "Decoded sentence: HH W AY T \n",
      " \n",
      "-\n",
      "Input sentence: ['HH', 'W', 'AY', 'T']\n",
      "Decoded sentence: HH W AY T \n",
      " \n",
      "-\n",
      "Input sentence: ['HH', 'W', 'AY', 'T']\n",
      "Decoded sentence: HH W AY T \n",
      " \n",
      "-\n",
      "Input sentence: ['W', 'AY']\n",
      "Decoded sentence: HH W AY T \n",
      " \n",
      "-\n",
      "Input sentence: ['W', 'AY']\n",
      "Decoded sentence: HH W AY T \n",
      " \n",
      "-\n",
      "Input sentence: ['HH', 'W', 'AY']\n",
      "Decoded sentence: HH W AY T \n",
      " \n",
      "-\n",
      "Input sentence: ['HH', 'W', 'AY']\n",
      "Decoded sentence: HH W AY T \n",
      " \n",
      "-\n",
      "Input sentence: ['W', 'AH', 'T']\n",
      "Decoded sentence: W AA S P \n",
      " \n",
      "-\n",
      "Input sentence: ['W', 'AH', 'T']\n",
      "Decoded sentence: W AA S P \n",
      " \n",
      "-\n",
      "Input sentence: ['HH', 'W', 'AH', 'T']\n",
      "Decoded sentence: W AA S P \n",
      " \n",
      "-\n",
      "Input sentence: ['HH', 'W', 'AH', 'T']\n",
      "Decoded sentence: W AA S P \n",
      " \n",
      "-\n",
      "Input sentence: ['L', 'AY', 'K']\n",
      "Decoded sentence: HH W AY T \n",
      " \n",
      "-\n",
      "Input sentence: ['L', 'AY', 'K']\n",
      "Decoded sentence: HH W AY T \n",
      " \n",
      "-\n",
      "Input sentence: ['B', 'L', 'AE', 'K']\n",
      "Decoded sentence: B L AE K \n",
      " \n",
      "-\n",
      "Input sentence: ['B', 'R', 'EY', 'K']\n",
      "Decoded sentence: B L AE K \n",
      " \n",
      "-\n",
      "Input sentence: ['AO', 'R', 'AH', 'N', 'JH']\n",
      "Decoded sentence: AO R AH N JH \n",
      "-\n",
      "Input sentence: ['AO', 'R', 'AH', 'N', 'JH']\n",
      "Decoded sentence: AO R AH N JH \n",
      "-\n",
      "Input sentence: ['AO', 'R', 'IH', 'N', 'JH']\n",
      "Decoded sentence: AO R AH N JH \n",
      "-\n",
      "Input sentence: ['AO', 'R', 'IH', 'N', 'JH']\n",
      "Decoded sentence: AO R AH N JH \n",
      "-\n",
      "Input sentence: ['R', 'EY', 'N']\n",
      "Decoded sentence: AO R IH N JH \n",
      "-\n",
      "Input sentence: ['R', 'EY', 'N']\n",
      "Decoded sentence: AO R IH N JH \n",
      "-\n",
      "Input sentence: ['P', 'ER', 'P', 'AH', 'L']\n",
      "Decoded sentence: P ER P AH L \n",
      " \n",
      "-\n",
      "Input sentence: ['K', 'AH', 'L', 'IH', 'P', 'S', 'OW']\n",
      "Decoded sentence: P ER P AH L \n",
      " \n",
      "-\n",
      "Input sentence: ['HH', 'EH', 'L', 'P']\n",
      "Decoded sentence: HH IH L \n",
      " \n",
      "-\n",
      "Input sentence: ['Y', 'EH', 'L', 'OW']\n",
      "Decoded sentence: Y EH L OW \n",
      " \n",
      "-\n",
      "Input sentence: ['P', 'IH', 'NG', 'K']\n",
      "Decoded sentence: P IH NG K \n",
      " \n",
      "-\n",
      "Input sentence: ['S', 'P', 'IY', 'K']\n",
      "Decoded sentence: P IH NG K \n",
      " \n",
      "-\n",
      "Input sentence: ['P', 'IH', 'K']\n",
      "Decoded sentence: P IH NG K \n",
      " \n",
      "-\n",
      "Input sentence: ['S', 'ER', 'K', 'AH', 'L']\n",
      "Decoded sentence: S ER K AH L \n",
      " \n",
      "-\n",
      "Input sentence: ['S', 'K', 'W', 'EH', 'R']\n",
      "Decoded sentence: S K W EH R \n",
      " \n",
      "-\n",
      "Input sentence: ['S', 'K', 'R', 'IY', 'N']\n",
      "Decoded sentence: S K W EH R \n",
      " \n",
      "-\n",
      "Input sentence: ['S', 'K', 'R', 'UW']\n",
      "Decoded sentence: S K W EH R \n",
      " \n",
      "-\n",
      "Input sentence: ['S', 'K', 'W', 'ER', 'AH', 'L']\n",
      "Decoded sentence: S K W EH R \n",
      " \n",
      "-\n",
      "Input sentence: ['S', 'T', 'AA', 'R']\n",
      "Decoded sentence: S T AA R \n",
      " \n",
      "-\n",
      "Input sentence: ['S', 'T', 'AA', 'R', 'T']\n",
      "Decoded sentence: S T AA R \n",
      " \n",
      "-\n",
      "Input sentence: ['S', 'T', 'AA', 'P']\n",
      "Decoded sentence: D AO G \n",
      " \n",
      "-\n",
      "Input sentence: ['T', 'R', 'AY', 'AE', 'NG', 'G', 'AH', 'L']\n",
      "Decoded sentence: T R AY AE NG \n",
      "-\n",
      "Input sentence: ['CH', 'AH', 'K']\n",
      "Decoded sentence: T R AY AE NG \n",
      "-\n",
      "Input sentence: ['R', 'EH', 'K', 'T', 'AE', 'NG', 'G', 'AH', 'L']\n",
      "Decoded sentence: R EH K T AE NG \n",
      "-\n",
      "Input sentence: ['R', 'EY', 'T']\n",
      "Decoded sentence: R EH K T AE NG \n",
      "-\n",
      "Input sentence: ['R', 'EH', 'D', 'IY']\n",
      "Decoded sentence: R EH D IH NG \n",
      "-\n",
      "Input sentence: ['T', 'UW']\n",
      "Decoded sentence: HH AE M S T ER \n",
      "-\n",
      "Input sentence: ['T', 'IH']\n",
      "Decoded sentence: V EH JH T AH \n",
      "-\n",
      "Input sentence: ['T', 'AH']\n",
      "Decoded sentence: V EH JH T AH \n",
      "-\n",
      "Input sentence: ['G', 'OW']\n",
      "Decoded sentence: G OW \n",
      " \n",
      "-\n",
      "Input sentence: ['HH', 'AA', 'R', 'T']\n",
      "Decoded sentence: HH AA R T \n",
      " \n",
      "-\n",
      "Input sentence: ['HH', 'AH', 'L', 'OW']\n",
      "Decoded sentence: HH EH R \n",
      " \n",
      "-\n",
      "Input sentence: ['HH', 'EH', 'L', 'OW']\n",
      "Decoded sentence: HH EH R \n",
      " \n",
      "-\n",
      "Input sentence: ['HH', 'AA', 'T']\n",
      "Decoded sentence: HH AA T \n",
      " \n",
      "-\n",
      "Input sentence: ['AE', 'R', 'OW']\n",
      "Decoded sentence: AE R OW \n",
      " \n",
      "-\n",
      "Input sentence: ['AE', 'R', 'OW']\n",
      "Decoded sentence: AE R OW \n",
      " \n",
      "-\n",
      "Input sentence: ['EH', 'R', 'OW']\n",
      "Decoded sentence: AE R OW \n",
      " \n",
      "-\n",
      "Input sentence: ['EH', 'R', 'OW']\n",
      "Decoded sentence: AE R OW \n",
      " \n",
      "-\n",
      "Input sentence: ['HH', 'AH', 'L', 'OW']\n",
      "Decoded sentence: HH EH R \n",
      " \n",
      "-\n",
      "Input sentence: ['HH', 'AH', 'L', 'OW']\n",
      "Decoded sentence: HH EH R \n",
      " \n",
      "-\n",
      "Input sentence: ['HH', 'EH', 'L', 'OW']\n",
      "Decoded sentence: HH EH R \n",
      " \n",
      "-\n",
      "Input sentence: ['HH', 'EH', 'L', 'OW']\n",
      "Decoded sentence: HH EH R \n",
      " \n",
      "-\n",
      "Input sentence: ['EH', 'R', 'AH']\n",
      "Decoded sentence: AE R OW \n",
      " \n",
      "-\n",
      "Input sentence: ['EH', 'R', 'AH']\n",
      "Decoded sentence: AE R OW \n",
      " \n",
      "-\n",
      "Input sentence: ['IH', 'R', 'AH']\n",
      "Decoded sentence: EH R OW \n",
      " \n",
      "-\n",
      "Input sentence: ['IH', 'R', 'AH']\n",
      "Decoded sentence: EH R OW \n",
      " \n",
      "-\n",
      "Input sentence: ['EH', 'R', 'IH', 'K']\n",
      "Decoded sentence: EH R OW \n",
      " \n",
      "-\n",
      "Input sentence: ['EH', 'R', 'IH', 'K']\n",
      "Decoded sentence: EH R OW \n",
      " \n",
      "-\n",
      "Input sentence: ['K', 'R', 'AO', 'S']\n",
      "Decoded sentence: K R AO S \n",
      " \n",
      "-\n",
      "Input sentence: ['K', 'L', 'OW', 'S']\n",
      "Decoded sentence: F AO R W ER D \n",
      "-\n",
      "Input sentence: ['K', 'L', 'OW', 'Z']\n",
      "Decoded sentence: F AO R W ER D \n",
      "-\n",
      "Input sentence: ['D', 'AY', 'M', 'AH', 'N', 'D']\n",
      "Decoded sentence: D AY M AH N D \n",
      "-\n",
      "Input sentence: ['D', 'AY', 'M', 'AH', 'N', 'D', 'Z']\n",
      "Decoded sentence: D AY M AH N D \n",
      "-\n",
      "Input sentence: ['L', 'EH', 'F', 'T']\n",
      "Decoded sentence: L EH F T \n",
      " \n",
      "-\n",
      "Input sentence: ['L', 'AE', 'F']\n",
      "Decoded sentence: L EH F T \n",
      " \n",
      "-\n",
      "Input sentence: ['L', 'AE', 'P']\n",
      "Decoded sentence: L EH F T \n",
      " \n",
      "-\n",
      "Input sentence: ['R', 'AY', 'T']\n",
      "Decoded sentence: R AY T \n",
      " \n",
      "-\n",
      "Input sentence: ['R', 'AY', 'T', 'S']\n",
      "Decoded sentence: R AY T \n",
      " \n",
      "-\n",
      "Input sentence: ['AH', 'P']\n",
      "Decoded sentence: SH ER T \n",
      " \n",
      "-\n",
      "Input sentence: ['AE', 'P']\n",
      "Decoded sentence: AH P \n",
      " \n",
      "-\n",
      "Input sentence: ['P', 'AE', 'T']\n",
      "Decoded sentence: AH P \n",
      " \n",
      "-\n",
      "Input sentence: ['D', 'AW', 'N']\n",
      "Decoded sentence: D AW N \n",
      " \n",
      "-\n",
      "Input sentence: ['D', 'AH', 'N']\n",
      "Decoded sentence: D AW N \n",
      " \n",
      "-\n",
      "Input sentence: ['F', 'OW', 'N']\n",
      "Decoded sentence: D AW N \n",
      " \n",
      "-\n",
      "Input sentence: ['JH', 'AA', 'N']\n",
      "Decoded sentence: D AW N \n",
      " \n",
      "-\n",
      "Input sentence: ['S', 'T', 'AA', 'P']\n",
      "Decoded sentence: D AO G \n",
      " \n",
      "-\n",
      "Input sentence: ['F', 'OW', 'N']\n",
      "Decoded sentence: D AW N \n",
      " \n",
      "-\n",
      "Input sentence: ['F', 'AO', 'R', 'W', 'ER', 'D', 'Z']\n",
      "Decoded sentence: F AO R W ER D \n",
      "-\n",
      "Input sentence: ['F', 'AO', 'R', 'W', 'ER', 'D']\n",
      "Decoded sentence: F AO R W ER D \n",
      "-\n",
      "Input sentence: ['K', 'L', 'OW', 'S']\n",
      "Decoded sentence: F AO R W ER D \n",
      "-\n",
      "Input sentence: ['K', 'L', 'OW', 'Z']\n",
      "Decoded sentence: F AO R W ER D \n",
      "-\n",
      "Input sentence: ['F', 'L', 'AW', 'ER', 'Z']\n",
      "Decoded sentence: F AO R W ER D \n",
      "-\n",
      "Input sentence: ['F', 'AA', 'L', 'OW']\n",
      "Decoded sentence: F AO R W ER D \n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    # print(encoder_input_data[seq_index : seq_index + 1])\n",
    "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
    "#     print(input_seq)\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", input_data_phonics_list[seq_index])\n",
    "    print(\"Decoded sentence:\", decoded_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lstm_seq2seq",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
